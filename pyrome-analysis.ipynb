{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9d7a19-874e-40ee-82e1-c788459d3f03",
   "metadata": {},
   "source": [
    "# FEDS vs. NIFC overlap per pyrome "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f8583-94bd-4e96-825c-8d7c95699d82",
   "metadata": {},
   "source": [
    "### Current project status \n",
    "As of August 16th. \n",
    "\n",
    "- Getting close to done crunching through FEDS ArchiveCONUS on DPS. See notebook page 96 for job tracker. When that is done, I will have CONUS-wide archival datasets for 2018-2023.\n",
    "- See `data-comparison.ipynb` for current info on different options for reference datasets (NIFC and alternatives).\n",
    "- I have added read local file capability to FEDS-PEC and parallelized the computations in there.\n",
    "- In this notebook, I have scripts for generating per-pyrome statistics from FEDS-PEC results and for creating an interactive map \n",
    "\n",
    "Next steps for analysis: \n",
    "- Finish ArchiveCONUS on DPS\n",
    "- Choose reference dataset (Current thought: MTBS for very large fires, supplement with cleaned NIFC data for smaller fires. For all of those, we are looking at final fire perimeters due to that being what we have to work with from reported perimeter datasets generally/at a large scale. The large fires should be fairly straightforward to evaluate; smaller fires requires a). more cleaning of NIFC data (there are some fires with multiple perimeters and b). more thought as to how we are matching fires, as we may have small fires with no overlap, but that actually do reflect the same incident.) Finally, we should do some analysis of what data we have available to evaluate false positive and false negative rates for FEDS. This is tricky, because a FEDS fire with no reported NIFC match may well have been real, and just didnt get collected, or it could have been made up or a non-wildfire. On the other hand, we should expect that most NIFC perimeters should have been picked up by FEDS at some point, as long as they burned long enough to be caught in at least one overpass, right? \n",
    "- Follow up: use Lisa's daily IR data (california only) to do more detailed case studies of perimeter agreement per timestep for a given fire. This would be helpful for assessing performance during a fire, which may be more insightful than final fire perimeter performance for many NRT and novel applications. Because satellite derived burned area datasets exist already- a big part of the usefulness of FEDS comes from its potential for fire spread research.\n",
    "- Follow up: use FS hierarchical ecosystem outlines to aggregate onto a scale that is larger than pyromes for larger sample size for statistics. Pyromes might be too small to use as a unit of analysis given the size of our dataset currently.\n",
    "- Once dataset has been decided, swap it in here to generate interactive map (may also want to try lonboard if that is unwieldy) and per-pyrome stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6fc35-3272-4773-97cb-a4823403ffd8",
   "metadata": {},
   "source": [
    "## Data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f8ac7-b80c-4d67-9a98-8187841dd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd \n",
    "# gpd.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d06d0-0187-4a20-8616-3f637c9ce2ea",
   "metadata": {},
   "source": [
    "### FEDS v3 perimeters \n",
    "\n",
    "Generated July-August 2024 using [FEDS v3](https://github.com/Earth-Information-System/fireatlas/tree/primarykeyv2) using settings as defined in the following `.env` file, which should be comparable to those used in v2 runs. \n",
    "\n",
    "```\n",
    "FEDS_FTYPE_OPT=\"CA\"\n",
    "FEDS_CONT_OPT=\"CA\"\n",
    "FEDS_EPSG_CODE=9311\n",
    "FEDS_FIRE_NRT=\"False\"\n",
    "FEDS_FIRE_SOURCE=\"SNPP\"\n",
    "FEDS_remove_static_sources=\"True\"\n",
    "```\n",
    "\n",
    "FEDS v3 was run in increments like so: `python fireatlas/FireRunDaskCoordinator.py --regnm=\"ArchiveCONUS2019\" --bbox=\"[-126.401171875,24.071240929282325,-61.36210937500001,49.40003415463647]\" --tst=\"[2019,1,1,\\\"AM\\\"]\" --ted=\"[2019,2,1,\\\"PM\\\"]\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a3512-ba88-482a-b06f-5972a0ecfa47",
   "metadata": {},
   "source": [
    "To coordinate work, I used the `manual-v3.yaml` (workflow)[https://github.com/Earth-Information-System/fireatlas/blob/2878c0df1b5f031eddbf9f3d4ab870930238b9b4/.github/workflows/manual-v3.yaml] to submit jobs in increments of 3 months each to the MAAP DPS batch computing environment. Example json params for manual v3 workflow: `{\"regnm\": \"ArchiveCONUS2019\", \"bbox\": \"[-126.401171875,24.071240929282325,-61.36210937500001,49.40003415463647]\", \"tst\": \"[2019,1,1,\\\"AM\\\"]\", \"ted\": \"[2019,4,1,\\\"PM\\\"]\", \"operation\": \"--coordinate-all\"}`. This operation cannot be temporally parallelized, so it is important that the previous job has finished before the next increment job is submitted. This allows the second job to find and read in the allfires and allpixels files saved by the first job, picking up from where that job left off. The only reason that jobs needed to be split into increments was that if I run a whole year at once, they hit the 24 hour job limit configured in DPS and are killed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbb196-80d0-446c-bf99-f714bdcc9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feds_v3_filepath = \"/projects/shared-buckets/gsfc_landslides/FEDSoutput-v3/ArchiveCONUS2019/2019/allfires_20191231_PM.parq\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09dc67b-9e30-4696-83f0-98807cfaeed2",
   "metadata": {},
   "source": [
    "### NIFC perimeters\n",
    "\n",
    "EDIT: for reported perimeters, currently exploring different dataset options and pros/cons. See `data-comparison.ipynb`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4275-8f4b-4299-b060-a0112cd6f0c4",
   "metadata": {},
   "source": [
    "### Pyrome boundaries \n",
    "\n",
    "Source: Short, Karen C.; Grenfell, Isaac C.; Riley, Karin L.; Vogler, Kevin C. 2020. Pyromes of the conterminous United States. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.2737/RDS-2020-0020\n",
    "\n",
    "Downloaded and available in `./data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f5df6-abdf-4d35-9b02-49af5ff0b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import matplotlib.image\n",
    "\n",
    "# img = matplotlib.image.imread('./data/pyrome_boundaries/Pyromes_CONUS_20200206.png')\n",
    "# imgplot = plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7ef68-5894-4bf7-8900-fb17d3591112",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyromes = gpd.read_file('./data/pyrome_boundaries/Pyromes_CONUS_20200206.shp').set_index('PYROME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b1eaf-9fd0-4130-9e2f-27f68dfc6fd8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07587446-3900-473a-88cc-0a7aa8a2855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd \n",
    "# gpd.show_versions()\n",
    "feds_v3_filepath = \"/projects/shared-buckets/gsfc_landslides/FEDSoutput-v3/ArchiveCONUS2019/2019/allfires_20191231_PM.parq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0378b19-081f-4157-b593-a566b50fdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utilities\n",
    "from Input_FEDS import InputFEDS\n",
    "from Input_Reference import InputReference\n",
    "from Output_Calculation import OutputCalculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648bc31e-74de-41ca-8aef-fa6874bbef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time \n",
    "year_start = 2019\n",
    "month_start = 7\n",
    "day_start = 1 \n",
    "hour_start = 0\n",
    "minute_start = 0\n",
    "second_start = 0\n",
    "tz_offset_hours_start = 0\n",
    "tz_offset_minutes_start = 0\n",
    "utc_offset_start = '00:00'\n",
    "\n",
    "# End time \n",
    "year_stop = 2019\n",
    "# month_stop = 12\n",
    "# day_stop = 31\n",
    "month_stop = 7\n",
    "day_stop = 2\n",
    "hour_stop = 0\n",
    "minute_stop = 0\n",
    "second_stop = 0\n",
    "tz_offset_hours_stop = 0\n",
    "tz_offset_minutes_stop = 0\n",
    "utc_offset_stop = '00:00'\n",
    "\n",
    "crs = 4326\n",
    "\n",
    "# BBOX FOR SEARCH - [lon, lat, lon, lat]\n",
    "search_bbox = [\"-126.401171875\",\"24.071240929282325\",\"-61.36210937500001\",\"49.40003415463647\"]\n",
    "\n",
    "# DAY SEARCH RANGE- acceptable distance warning to search from feds -> reference (e.g. if reference polygon is 8 days away, output a warning)\n",
    "# note by default, any results not of the same year are eliminated\n",
    "day_search_range = 7 \n",
    "\n",
    "\n",
    "# calc_in_parallel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d98af4-252d-4043-a63f-2413b95609ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEDS INPUT SETTINGS\n",
    "\n",
    "# read local\n",
    "feds_title = None \n",
    "feds_collection = feds_v3_filepath\n",
    "feds_access_type = \"local\"\n",
    "feds_limit = None\n",
    "feds_filter = False\n",
    "feds_apply_finalfire = True # only take latest fireID per fire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239edad-ea4a-4e98-854a-b4a5a69c3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCE INPUT SETTINGS \n",
    "ref_title =\"Historic_GeoMAC_Perimeters_2019\"\n",
    "ref_control_type = \"defined\" # or \"custom\"\n",
    "ref_custom_url = \"none\"\n",
    "ref_custom_read_type = \"none\"\n",
    "ref_filter = False # False or a valid query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22ce71-6628-4c4b-9698-3c0779e05339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT SETTINGS\n",
    "print_on = True\n",
    "plot_on = True\n",
    "name_for_output_file = \"test_run\" \n",
    "output_format=\"csv\" \n",
    "user_path = f\"/projects/my-private-bucket/FEDS-PEC\"\n",
    "output_maap_url = f\"{user_path}/{name_for_output_file}.{output_format}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3292c9-4d88-4246-abea-ca08224dc429",
   "metadata": {},
   "source": [
    "#### Argument processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ce61d-94da-419c-9232-6f159c660950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start date formatting\n",
    "search_start = Utilities.format_datetime(year_start, \n",
    "                                         month_start, \n",
    "                                         day_start, \n",
    "                                         hour_start, \n",
    "                                         minute_start, \n",
    "                                         second_start, \n",
    "                                         tz_offset_hours_start, \n",
    "                                         tz_offset_minutes_start,\n",
    "                                         utc_offset_start)\n",
    "# stop date formatting\n",
    "search_stop = Utilities.format_datetime(year_stop, \n",
    "                                        month_stop, \n",
    "                                        day_stop, \n",
    "                                        hour_stop, \n",
    "                                        minute_stop, \n",
    "                                        second_stop, \n",
    "                                        tz_offset_hours_stop, \n",
    "                                        tz_offset_minutes_stop,\n",
    "                                        utc_offset_stop)\n",
    "\n",
    "# bound check the bbox\n",
    "assert Utilities.check_bbox(search_bbox), f\"ERR: passed bbox {search_bbox} is not valid; check bounds\"\n",
    "assert  Utilities.check_crs(crs), f\"ERR: invalid crs provided {crs}; please enter valid ESPG CRS number\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431bcc78-67e3-4503-b909-b56a530aaf4a",
   "metadata": {},
   "source": [
    "### Run calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162589c-8b71-4bdd-adc6-cd24b38b4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "feds_firenrt = InputFEDS(\n",
    "                 feds_title, \n",
    "                 feds_collection, \n",
    "                 search_start,\n",
    "                 search_stop,\n",
    "                 search_bbox,\n",
    "                 crs,\n",
    "                 feds_access_type,\n",
    "                 feds_limit,\n",
    "                 feds_filter,\n",
    "                 feds_apply_finalfire\n",
    "                )\n",
    "\n",
    "feds_firenrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd1b9b-1e9f-4452-a2ce-f4647fe99e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nifc_search = InputReference( \n",
    "                 search_start,\n",
    "                 search_stop,\n",
    "                 search_bbox,\n",
    "                 crs,\n",
    "                 ref_title,\n",
    "                 ref_control_type,\n",
    "                 ref_custom_url,\n",
    "                 ref_custom_read_type,\n",
    "                 ref_filter,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199f6c2-1ca4-49f1-8c54-8f4dfda6c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "my_output = OutputCalculation(\n",
    "                feds_firenrt,\n",
    "                nifc_search,\n",
    "                output_format, \n",
    "                output_maap_url,\n",
    "                day_search_range,\n",
    "                print_on,\n",
    "                plot_on, \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46f870-46a6-4b03-9920-0be6c935c2b5",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e3679-566c-4120-baf4-c8e62bfc40dd",
   "metadata": {},
   "source": [
    "### Per-pyrome analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4fbd28-f3f5-4aee-80d5-5ec15b1861e5",
   "metadata": {},
   "source": [
    "#### Summary stats over CONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f70fd-946d-4888-ab52-7cce4e141997",
   "metadata": {},
   "source": [
    "So: are we only looking at matches? \n",
    "\n",
    "Yes. Several reasons:\n",
    "- If a FEDS perim does not match a NIFC perim, it is more likely that there isn't a matching fire in NIFC than that there is a perim for the same incident, but they are totally non-overlapping.\n",
    "- i would expect that large fires will intersect somewhat spatially in almost all cases.\n",
    "\n",
    "What this does not tell us about: \n",
    "- of all NIFC perimeters, how many have FEDS matches? (If FEDS misses a lot of large NIFC fires, that is a problem)\n",
    "- of all FEDS perimeters, how many have NIFC matches? (we expect that many FEDS fires will not be in NIFC- this could be due to them actually being false positives or to the fact that many actual fires are not captured in the NIFC base)\n",
    "\n",
    "When they are looking at similar things, how well do they agree? \n",
    "\n",
    "How can we learn where the perimeters are flawed so we can build that understanding into future uses? \n",
    "\n",
    "For known matches are we seeing systematic errors in different pyromes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97437ab6-c9d5-4e7a-8b9f-b05c81076243",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results = gpd.read_file(\"/projects/my-private-bucket/FEDS-PEC/ArchiveCONUS2019-julyaugustsept.csv\")\n",
    "results['ref_polygon'] = gpd.GeoSeries.from_wkt(results['ref_polygon'])\n",
    "results['feds_polygon'] = gpd.GeoSeries.from_wkt(results['feds_polygon'])\n",
    "\n",
    "print(\"-------------------\") \n",
    "print(\"CONUS column mean values:\")\n",
    "for stat in ['ratio', 'accuracy', 'recall', 'iou', 'f1', 'symm_ratio']:\n",
    "    results[stat] = pd.to_numeric(results[stat])\n",
    "    print(f\"{stat} mean: {results[stat].mean():.3f}\")\n",
    "\n",
    "print(\"-------------------\\n\")\n",
    "\n",
    "# pyromes = pyromes.to_crs(feds_firenrt.crs)\n",
    "pyromes = pyromes.to_crs(epsg=4326) \n",
    "\n",
    "stats = gpd.GeoDataFrame(columns=['pyrome_name', 'ratio', 'accuracy', 'recall', 'iou', 'f1', 'symm_ratio']).set_index('pyrome_name')\n",
    "\n",
    "for index, pyrome in pyromes.iterrows():\n",
    "    print(f\"{pyrome.NAME}:\")\n",
    "\n",
    "    # idea: # select rows where ref_polyon is half or more within pyrome geometry\n",
    "    # current: select any row where ref_polygolkjlkjn intersects pyrome (possibility of duplication along boundaries) \n",
    "    subset = results[results['ref_polygon'].intersects(pyrome.geometry)] \n",
    "\n",
    "    print(f\"\\t{len(subset)} matches\")\n",
    "    \n",
    "    if len(subset) < 1:\n",
    "        pass\n",
    "    else: \n",
    "        for stat in ['ratio', 'accuracy', 'recall', 'iou', 'f1', 'symm_ratio']:\n",
    "            print(f\"\\t{stat} mean: {subset[stat].mean():.3f}\")\n",
    "            stats.at[pyrome.NAME, stat] = subset[stat].mean()\n",
    "\n",
    "\n",
    "outpath = f\"{user_path}/{name_for_output_file}_pyrome_stats.csv\"\n",
    "# stats.to_csv(outpath)\n",
    "\n",
    "# add row with nan vals for all pyromes that dont have any matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fa91a-c7f4-441f-bf02-429258c04277",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96327d-7c2a-4147-8012-609b1daf2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd \n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "df = pd.read_csv(\"~/my-public-bucket/ArchiveCONUS2019-nifc-matches-june-sept.csv\")\n",
    "df = df.drop([\"Unnamed: 0\", \"geometry\"], axis=1)\n",
    "gdf = gpd.GeoDataFrame(df)\n",
    "\n",
    "gdf['ref_polygon'] = gpd.GeoSeries.from_wkt(gdf['ref_polygon']).set_crs(epsg=4326)\n",
    "gdf['feds_polygon'] = gpd.GeoSeries.from_wkt(gdf['feds_polygon']).set_crs(epsg=4326)\n",
    "gdf = gdf.set_geometry('feds_polygon')\n",
    "\n",
    "ref_polygon = gdf[['ref_polygon', 'incident_name', 'ref_timestamp']].set_geometry('ref_polygon')\n",
    "feds_polygon = gdf[['feds_polygon', 'incident_name', 'feds_timestamp']].set_geometry('feds_polygon') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e8c01-807e-4b02-97df-10ea9f9609d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyromes = gpd.read_file('./data/pyrome_boundaries/Pyromes_CONUS_20200206.shp').set_index('PYROME')\n",
    "pyromes = pyromes.to_crs(epsg=4326) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eba047-8e11-4b7c-823f-2579223eeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utilities\n",
    "from Input_Reference import InputReference\n",
    "\n",
    "# Start time \n",
    "year_start = 2019\n",
    "month_start = 6\n",
    "day_start = 1 \n",
    "hour_start = 0\n",
    "minute_start = 0\n",
    "second_start = 0\n",
    "tz_offset_hours_start = 0\n",
    "tz_offset_minutes_start = 0\n",
    "utc_offset_start = '00:00'\n",
    "\n",
    "# End time \n",
    "year_stop = 2019\n",
    "# month_stop = 12\n",
    "# day_stop = 31\n",
    "month_stop = 10\n",
    "day_stop = 1\n",
    "hour_stop = 0\n",
    "minute_stop = 0\n",
    "second_stop = 0\n",
    "tz_offset_hours_stop = 0\n",
    "tz_offset_minutes_stop = 0\n",
    "utc_offset_stop = '00:00'\n",
    "\n",
    "crs = 4326\n",
    "\n",
    "# BBOX FOR SEARCH - [lon, lat, lon, lat]\n",
    "search_bbox = [\"-126.401171875\",\"24.071240929282325\",\"-61.36210937500001\",\"49.40003415463647\"]\n",
    "\n",
    "# DAY SEARCH RANGE- acceptable distance warning to search from feds -> reference (e.g. if reference polygon is 8 days away, output a warning)\n",
    "# note by default, any results not of the same year are eliminated\n",
    "day_search_range = 7 \n",
    "\n",
    "# REFERENCE INPUT SETTINGS \n",
    "ref_title =\"Historic_GeoMAC_Perimeters_2019\"\n",
    "ref_control_type = \"defined\" # or \"custom\"\n",
    "ref_custom_url = \"none\"\n",
    "ref_custom_read_type = \"none\"\n",
    "ref_filter = False # False or a valid query\n",
    "\n",
    "# start date formatting\n",
    "search_start = Utilities.format_datetime(year_start, \n",
    "                                         month_start, \n",
    "                                         day_start, \n",
    "                                         hour_start, \n",
    "                                         minute_start, \n",
    "                                         second_start, \n",
    "                                         tz_offset_hours_start, \n",
    "                                         tz_offset_minutes_start,\n",
    "                                         utc_offset_start)\n",
    "# stop date formatting\n",
    "search_stop = Utilities.format_datetime(year_stop, \n",
    "                                        month_stop, \n",
    "                                        day_stop, \n",
    "                                        hour_stop, \n",
    "                                        minute_stop, \n",
    "                                        second_stop, \n",
    "                                        tz_offset_hours_stop, \n",
    "                                        tz_offset_minutes_stop,\n",
    "                                        utc_offset_stop)\n",
    "\n",
    "# bound check the bbox\n",
    "assert Utilities.check_bbox(search_bbox), f\"ERR: passed bbox {search_bbox} is not valid; check bounds\"\n",
    "assert  Utilities.check_crs(crs), f\"ERR: invalid crs provided {crs}; please enter valid ESPG CRS number\"\n",
    "\n",
    "nifc_search = InputReference( \n",
    "                 search_start,\n",
    "                 search_stop,\n",
    "                 search_bbox,\n",
    "                 crs,\n",
    "                 ref_title,\n",
    "                 ref_control_type,\n",
    "                 ref_custom_url,\n",
    "                 ref_custom_read_type,\n",
    "                 ref_filter,\n",
    "                )\n",
    "\n",
    "# Was getting some NIFC matches outside of date range, so re-filtering here (noticed due to Kincade fire) \n",
    "\n",
    "start = pd.to_datetime(search_start).to_datetime64()\n",
    "stop = pd.to_datetime(search_stop).to_datetime64()\n",
    "\n",
    "filtered_nifc = nifc_search.polygons[(nifc_search.polygons.DATE_CUR_STAMP >= start) & (nifc_search.polygons.DATE_CUR_STAMP <= stop)]\n",
    "\n",
    "filtered_nifc.DATE_CUR_STAMP = filtered_nifc.DATE_CUR_STAMP.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250933f2-c64a-449d-9fcf-2f1aa489ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = pd.to_datetime(search_start)\n",
    "# stop = pd.to_datetime(search_stop)\n",
    "print(f\"pre-filtering ref_polygon: {len(ref_polygon)}\") \n",
    "ref_polygon = ref_polygon[(pd.to_datetime(ref_polygon.ref_timestamp) >= start) & (pd.to_datetime(ref_polygon.ref_timestamp) <= stop)]\n",
    "print(f\"filtered: {len(ref_polygon)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f724c7-d738-44fe-b0ff-46e281696e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = folium.Map(center=[39.5, -119.5], zoom_start=15, min_zoom=10, max_bounds=True)\n",
    "m = folium.Map()\n",
    "\n",
    "esri_world_terrain = folium.TileLayer(\n",
    "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Terrain_Base/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr='Tiles &copy; Esri &mdash; Source: USGS, Esri, TANA, DeLorme, and NPS',\n",
    "    name='Esri WorldTerrain',\n",
    "    overlay=False,\n",
    "    control=False\n",
    ")\n",
    "\n",
    "esri_world_terrain.add_to(m)\n",
    "\n",
    "\n",
    "# @TODO need to filter down to only the latest perimeter from a given incident NIFC\n",
    "# groupby incident name, take latest should work OR just have fill opacity 1- then you cnt see. \n",
    "# @TODO could add popups with correct info; or, could just not. \n",
    "\n",
    "pyromes.explore(m=m, style_kwds={'fillOpacity': 0, 'weight': .75}, highlight_kwds={'fillOpacity':0}, color='black', name='Pyrome boundaries')\n",
    "\n",
    "filtered_nifc.explore(m=m, style_kwds={'fillOpacity': 0}, color='red', name='All NIFC perimeters (red)')\n",
    "\n",
    "ref_polygon.explore(m=m, style_kwds={'fillOpacity': .5}, color='blue', name='NIFC matched perimeters (blue)')\n",
    "\n",
    "feds_polygon.explore(m=m, style_kwds={'fillOpacity': .5}, color='orange', name='FEDS matched perimeters (orange)') \n",
    "\n",
    "folium.LayerControl(collapsed=False).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1834df42-25a8-4d86-92dc-22774efeb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"summer-2019-FEDS-vs-NIFC-by-pyrome.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07526de0-220a-40c3-a20b-29d2a60786ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo] *",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
